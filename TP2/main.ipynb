{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar librerias y leer datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./archivos-bd/data_uci.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis exploratorio de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primer contacto con los datos\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forma y cantidad de los datos\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver balance de las etiquetas\n",
    "print(data[\"riesgo\"].value_counts())\n",
    "\n",
    "sns.countplot(x=data[\"riesgo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columnas del dataset\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlacion entre variables\n",
    "corr = data.iloc[:, :5].corr()\n",
    "\n",
    "# Grafica con Seaborn de la matriz de correlación\n",
    "sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, annot=True, cmap=sns.diverging_palette(220, 20, as_cmap=True))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 5, figsize=(15, 4))\n",
    "fig.suptitle('Distribucion de los datos')\n",
    "sns.histplot(x=data[\"edad\"], ax=ax[0])\n",
    "ax[0].set_title('edad')\n",
    "sns.histplot(x=data[\"td\"], ax=ax[1])\n",
    "ax[1].set_title('td')\n",
    "sns.histplot(x=data[\"par\"], ax=ax[2])\n",
    "ax[2].set_title('par')\n",
    "sns.histplot(x=data[\"fcm\"], ax=ax[3])\n",
    "ax[3].set_title('fcm')\n",
    "sns.histplot(x=data[\"col\"], ax=ax[4])\n",
    "ax[4].set_title('col')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de valores nulos\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis de valores por columna para determinar si había valores extraños\n",
    "\n",
    "print(\"Edad:\",data[\"edad\"].unique())\n",
    "\n",
    "print(\"Dolor toraxico:\", data[\"td\"].unique())\n",
    "\n",
    "print(\"Presion arterial reposo:\",data[\"par\"].unique())\n",
    "\n",
    "print(\"Colesterol\", data[\"col\"].unique())\n",
    "\n",
    "print(\"Frecuencia cardiaca maxima:\", data[\"fcm\"].unique())\n",
    "\n",
    "print(\"Riesgo:\", data[\"riesgo\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento y normalización de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos con Frecuencia Cardíaca igual a 0\n",
    "data[data[\"fcm\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos con Presion Arterial en Reposo igual a 0\n",
    "data[data[\"par\"] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazo de valores iguales a 0 en Frecuencia Cardíaca por la media de la columna\n",
    "mediaFcm = int(data[data[\"fcm\"] != 0][\"fcm\"].mean())\n",
    "\n",
    "data[\"fcm\"] = data[\"fcm\"].replace(0, mediaFcm)\n",
    "\n",
    "print(data[data[\"fcm\"] == 0])\n",
    "\n",
    "data[\"fcm\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazo de valores iguales a -1 en Presión Arterial en Reposo por la media de la columna\n",
    "mediaFcm = int(data[data[\"par\"] != -1][\"par\"].mean())\n",
    "\n",
    "data[\"par\"] = data[\"par\"].replace(-1, mediaFcm)\n",
    "\n",
    "print(data[data[\"par\"] == -1])\n",
    "\n",
    "data[\"par\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información sobre las medias, distribución, dispersiones y otros atributos estadísticos de los datos\n",
    "sns.boxplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observacion\n",
    "\n",
    "Encontramos que hay un valor de colesterol que esta completametne alejado de los valores posibles ya que es más del doble del nivel de colesterol aceptado.\n",
    "La decisión que vamos a tomar es la de reemplazar el valor por el valor de colesterol medio porque pensamos que este valor tiene un error de medicion. Esto también lo pensamos porque los valores de los otros atributos que acompañan a este dato son adecuados y tiene un riesgo de cardiopatia bajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busqueda del valor atípico\n",
    "data[data[\"col\"] >= 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazo de valores atípicos en Colesterol por la media de la columna\n",
    "mediaCol = int(data[data[\"col\"] != 564][\"col\"].mean())\n",
    "\n",
    "data[\"col\"] = data[\"col\"].replace(564, mediaCol)\n",
    "\n",
    "print(data[data[\"col\"] == 564])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanceo del conjunto de datos\n",
    "oversample = RandomOverSampler(sampling_strategy=\"minority\")\n",
    "\n",
    "data_sin_riesgo = data.iloc[:, :5]\n",
    "data_riesgo = data[\"riesgo\"]\n",
    "\n",
    "data_sin_riesgo_over, data_riesgo_over = oversample.fit_resample(data_sin_riesgo, data_riesgo)\n",
    "\n",
    "sns.countplot(x=data_riesgo_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización del dataset\n",
    "normalized_df=(data_sin_riesgo_over-data_sin_riesgo_over.min())/(data_sin_riesgo_over.max()-data_sin_riesgo_over.min())\n",
    "\n",
    "sns.boxplot(normalized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra del dataset normalizado\n",
    "normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación de variables categóricas a numéricas\n",
    "data_riesgo_over = data_riesgo_over.map({'alto':1,'bajo':0})\n",
    "data_riesgo_over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División del conjunto de datos\n",
    "x = normalized_df.copy()\n",
    "y = data_riesgo_over.copy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=1)\n",
    "\n",
    "print(x.shape, x_train.shape, x_test.shape)\n",
    "print(y.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar un modelo de Regresión Logística\n",
    "model_log_reg = LogisticRegression(verbose=2)\n",
    "\n",
    "# Entrenar el modelo con el conjunto de entrenamiento\n",
    "model_log_reg.fit(x_train, y_train)\n",
    "\n",
    "# Calculando la precisión para el conjunto de entrenamiento\n",
    "x_train_prediction = model_log_reg.predict(x_train)\n",
    "train_accuracy = accuracy_score(x_train_prediction, y_train)\n",
    "train_recall = recall_score(x_train_prediction, y_train)\n",
    "train_f1 = f1_score(x_train_prediction, y_train)\n",
    "print(f'Entrenamiento - Accuracy: {train_accuracy:.2f}')\n",
    "print(f'Entrenamiento - Recall: {train_recall:.2f}')\n",
    "print(f'Entrenamiento - F1-Score: {train_f1:.2f}')\n",
    "\n",
    "# Calculando la precisión para el conjunto de test\n",
    "x_test_prediction = model_log_reg.predict(x_test)\n",
    "test_accuracy = accuracy_score(x_test_prediction, y_test)\n",
    "test_recall = recall_score(x_test_prediction, y_test)\n",
    "test_f1 = f1_score(x_test_prediction, y_test)\n",
    "print(f'Test - Accuracy: {test_accuracy:.2f}')\n",
    "print(f'Test - Recall: {test_recall:.2f}')\n",
    "print(f'Test - F1-Score: {test_f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logística con regularización Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar un modelo de Regresión Logística\n",
    "model_log_reg = LogisticRegression(penalty=\"l1\", C=0.5, verbose=2, solver=\"liblinear\")\n",
    "\n",
    "# Entrenar el modelo con el conjunto de entrenamiento\n",
    "model_log_reg.fit(x_train, y_train)\n",
    "\n",
    "# Calculando la precisión para el conjunto de entrenamiento\n",
    "x_train_prediction = model_log_reg.predict(x_train)\n",
    "train_accuracy = accuracy_score(x_train_prediction, y_train)\n",
    "train_recall = recall_score(x_train_prediction, y_train)\n",
    "train_f1 = f1_score(x_train_prediction, y_train)\n",
    "print(f'Entrenamiento - Accuracy: {train_accuracy:.2f}')\n",
    "print(f'Entrenamiento - Recall: {train_recall:.2f}')\n",
    "print(f'Entrenamiento - F1-Score: {train_f1:.2f}')\n",
    "\n",
    "# Calculando la precisión para el conjunto de test\n",
    "x_test_prediction = model_log_reg.predict(x_test)\n",
    "test_accuracy = accuracy_score(x_test_prediction, y_test)\n",
    "test_recall = recall_score(x_test_prediction, y_test)\n",
    "test_f1 = f1_score(x_test_prediction, y_test)\n",
    "print(f'Test - Accuracy: {test_accuracy:.2f}')\n",
    "print(f'Test - Recall: {test_recall:.2f}')\n",
    "print(f'Test - F1-Score: {test_f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos un modelo Naive Bayes\n",
    "model_NB = GaussianNB()\n",
    "\n",
    "# Entrenar el modelo con el conjunto de entrenamiento\n",
    "model_NB.fit(x_train, y_train)\n",
    "\n",
    "# Calculando la precisión para el conjunto de entrenamiento\n",
    "x_train_prediction = model_NB.predict(x_train)\n",
    "train_accuracy = accuracy_score(x_train_prediction, y_train)\n",
    "train_recall = recall_score(x_train_prediction, y_train)\n",
    "train_f1 = f1_score(x_train_prediction, y_train)\n",
    "print(f'Entrenamiento - Accuracy: {train_accuracy:.2f}')\n",
    "print(f'Entrenamiento - Recall: {train_recall:.2f}')\n",
    "print(f'Entrenamiento - F1-Score: {train_f1:.2f}')\n",
    "\n",
    "# Calculando la precisión para el conjunto de test\n",
    "x_test_prediction = model_NB.predict(x_test)\n",
    "test_accuracy = accuracy_score(x_test_prediction, y_test)\n",
    "test_recall = recall_score(x_test_prediction, y_test)\n",
    "test_f1 = f1_score(x_test_prediction, y_test)\n",
    "print(f'Test - Accuracy: {test_accuracy:.2f}')\n",
    "print(f'Test - Recall: {test_recall:.2f}')\n",
    "print(f'Test - F1-Score: {test_f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest-Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros que probaremos cambiar\n",
    "k_range = [i for i in range(1, 21)]\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "\n",
    "# Instanciamos un GridSearch con validacion cruzada\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=7, scoring=\"recall\")\n",
    "\n",
    "grid_search = grid.fit(x_train, y_train)\n",
    "\n",
    "print(\"Score en el conjunto de tests: {:.2f}\".format(grid_search.score(x_test, y_test)))\n",
    "print(\"Mejores parámetros: {}\".format(grid_search.best_params_))\n",
    "print(\"Mejor Score de validacion Cruzada: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos un modelo KNN\n",
    "model_KNN = KNeighborsClassifier(grid_search.best_params_[\"n_neighbors\"])\n",
    "\n",
    "# Entrenar el modelo con el conjunto de entrenamiento\n",
    "model_KNN.fit(x_train, y_train)\n",
    "\n",
    "# Calculando la precisión para el conjunto de entrenamiento\n",
    "x_train_prediction = model_KNN.predict(x_train)\n",
    "train_accuracy = accuracy_score(x_train_prediction, y_train)\n",
    "train_recall = recall_score(x_train_prediction, y_train)\n",
    "train_f1 = f1_score(x_train_prediction, y_train)\n",
    "print(f'Entrenamiento - Accuracy: {train_accuracy:.2f}')\n",
    "print(f'Entrenamiento - Recall: {train_recall:.2f}')\n",
    "print(f'Entrenamiento - F1-Score: {train_f1:.2f}')\n",
    "\n",
    "# Calculando la precisión para el conjunto de test\n",
    "x_test_prediction = model_KNN.predict(x_test)\n",
    "test_accuracy = accuracy_score(x_test_prediction, y_test)\n",
    "test_recall = recall_score(x_test_prediction, y_test)\n",
    "test_f1 = f1_score(x_test_prediction, y_test)\n",
    "print(f'Test - Accuracy: {test_accuracy:.2f}')\n",
    "print(f'Test - Recall: {test_recall:.2f}')\n",
    "print(f'Test - F1-Score: {test_f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos un modelo RandomForest\n",
    "model_RFC = RandomForestClassifier(n_estimators=150)\n",
    "\n",
    "# Entrenar el modelo con el conjunto de entrenamiento\n",
    "model_RFC.fit(x_train, y_train)\n",
    "\n",
    "# Calculando la precisión para el conjunto de entrenamiento\n",
    "x_train_prediction = model_RFC.predict(x_train)\n",
    "train_accuracy = accuracy_score(x_train_prediction, y_train)\n",
    "train_recall = recall_score(x_train_prediction, y_train)\n",
    "train_f1 = f1_score(x_train_prediction, y_train)\n",
    "print(f'Entrenamiento - Accuracy: {train_accuracy:.2f}')\n",
    "print(f'Entrenamiento - Recall: {train_recall:.2f}')\n",
    "print(f'Entrenamiento - F1-Score: {train_f1:.2f}')\n",
    "\n",
    "# Calculando la precisión para el conjunto de test\n",
    "x_test_prediction = model_RFC.predict(x_test)\n",
    "test_accuracy = accuracy_score(x_test_prediction, y_test)\n",
    "test_recall = recall_score(x_test_prediction, y_test)\n",
    "test_f1 = f1_score(x_test_prediction, y_test)\n",
    "print(f'Test - Accuracy: {test_accuracy:.2f}')\n",
    "print(f'Test - Recall: {test_recall:.2f}')\n",
    "print(f'Test - F1-Score: {test_f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {'n_estimators': randint(50,500),\n",
    "              'max_depth': randint(1,20)}\n",
    "\n",
    "# Usar random search para encontrar los mejores hiperparámetros\n",
    "rand_search = RandomizedSearchCV(RandomForestClassifier(), \n",
    "                                 param_distributions = param_dist, \n",
    "                                 n_iter=5, \n",
    "                                 cv=5)\n",
    "\n",
    "# Entrenar random search\n",
    "rand_search.fit(x_train, y_train)\n",
    "\n",
    "# Crear una variable con el mejor modelo\n",
    "best_rf = rand_search.best_estimator_\n",
    "\n",
    "# Mostrar los mejores hiperparámetros\n",
    "print('Best hyperparameters:',  rand_search.best_params_)\n",
    "\n",
    "# Entrenar el modelo con el conjunto de entrenamiento\n",
    "best_rf.fit(x_train, y_train)\n",
    "\n",
    "# Calculando la precisión para el conjunto de entrenamiento\n",
    "x_train_prediction = best_rf.predict(x_train)\n",
    "train_accuracy = accuracy_score(x_train_prediction, y_train)\n",
    "train_recall = recall_score(x_train_prediction, y_train)\n",
    "train_f1 = f1_score(x_train_prediction, y_train)\n",
    "print(f'Entrenamiento - Accuracy: {train_accuracy:.2f}')\n",
    "print(f'Entrenamiento - Recall: {train_recall:.2f}')\n",
    "print(f'Entrenamiento - F1-Score: {train_f1:.2f}')\n",
    "\n",
    "# Calculando la precisión para el conjunto de test\n",
    "x_test_prediction = best_rf.predict(x_test)\n",
    "test_accuracy = accuracy_score(x_test_prediction, y_test)\n",
    "test_recall = recall_score(x_test_prediction, y_test)\n",
    "test_f1 = f1_score(x_test_prediction, y_test)\n",
    "print(f'Test - Accuracy: {test_accuracy:.2f}')\n",
    "print(f'Test - Recall: {test_recall:.2f}')\n",
    "print(f'Test - F1-Score: {test_f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrón Multicapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar un modelo de perceptron multicapa\n",
    "model_MLP = MLPClassifier(hidden_layer_sizes=(50, 100, 50), activation=\"relu\", max_iter=1500, alpha=2, solver=\"lbfgs\", verbose=0, random_state=2, tol=0.000000001, learning_rate=\"adaptive\")\n",
    "\n",
    "# Entrenar el modelo con el conjunto de entrenamiento\n",
    "model_MLP.fit(x_train, y_train)\n",
    "\n",
    "# Calculando la precisión para el conjunto de entrenamiento\n",
    "x_train_prediction = model_MLP.predict(x_train)\n",
    "train_accuracy = accuracy_score(x_train_prediction, y_train)\n",
    "train_recall = recall_score(x_train_prediction, y_train)\n",
    "train_f1 = f1_score(x_train_prediction, y_train)\n",
    "print(f'Entrenamiento - Accuracy: {train_accuracy:.2f}')\n",
    "print(f'Entrenamiento - Recall: {train_recall:.2f}')\n",
    "print(f'Entrenamiento - F1-Score: {train_f1:.2f}')\n",
    "\n",
    "# Calculando la precisión para el conjunto de test\n",
    "x_test_prediction = model_MLP.predict(x_test)\n",
    "test_accuracy = accuracy_score(x_test_prediction, y_test)\n",
    "test_recall = recall_score(x_test_prediction, y_test)\n",
    "test_f1 = f1_score(x_test_prediction, y_test)\n",
    "print(f'Test - Accuracy: {test_accuracy:.2f}')\n",
    "print(f'Test - Recall: {test_recall:.2f}')\n",
    "print(f'Test - F1-Score: {test_f1:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
