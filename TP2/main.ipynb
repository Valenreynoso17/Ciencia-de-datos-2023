{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./archivos-bd/data_uci.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"riesgo\"].value_counts()\n",
    "\n",
    "# plt.bar(data[\"riesgo\"].unique(), data[\"riesgo\"].value_counts())\n",
    "\n",
    "sns.countplot(x=data[\"riesgo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data.iloc[:, :5].corr()\n",
    "\n",
    "# Grafica con Seaborn de la matriz de correlación\n",
    "sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, annot=True, cmap=sns.diverging_palette(220, 20, as_cmap=True))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns\n",
    "\n",
    "print(\"Edad:\",data[\"edad\"].unique())\n",
    "\n",
    "print(\"Dolor toraxico:\", data[\"td\"].unique())\n",
    "\n",
    "print(\"Presion arterial reposo:\",data[\"par\"].unique())\n",
    "\n",
    "print(\"Colesterol\", data[\"col\"].unique())\n",
    "\n",
    "print(\"Frecuencia cardiaca maxima:\", data[\"fcm\"].unique())\n",
    "\n",
    "print(\"Riesgo:\", data[\"riesgo\"].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"fcm\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"par\"] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediaFcm = int(data[data[\"fcm\"] != 0][\"fcm\"].mean())\n",
    "\n",
    "data[\"fcm\"] = data[\"fcm\"].replace(0, mediaFcm)\n",
    "\n",
    "print(data[data[\"fcm\"] == 0])\n",
    "\n",
    "data[\"fcm\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediaFcm = int(data[data[\"par\"] != -1][\"par\"].mean())\n",
    "\n",
    "data[\"par\"] = data[\"par\"].replace(-1, mediaFcm)\n",
    "\n",
    "print(data[data[\"par\"] == -1])\n",
    "\n",
    "data[\"par\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sin_riesgo = data.iloc[:, :5]\n",
    "\n",
    "normalized_df=(data_sin_riesgo-data_sin_riesgo.min())/(data_sin_riesgo.max()-data_sin_riesgo.min())\n",
    "\n",
    "sns.boxplot(normalized_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observacion\n",
    "\n",
    "Encontramos que hay un valor de colesterol que esta completametne elejado de los valores posibles ya que es más del doble del nivel de colesterol aceptado.\n",
    "El procesamiendo que vamos a realizar es reemplazar el valor por el valor de colesterol medio porque pensamos que este valor tiene un error de medicion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"col\"] >= 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediaCol = int(data[data[\"col\"] != 564][\"col\"].mean())\n",
    "\n",
    "data[\"col\"] = data[\"col\"].replace(564, mediaCol)\n",
    "\n",
    "print(data[data[\"col\"] == 564])\n",
    "\n",
    "data_sin_riesgo = data.iloc[:, :5]\n",
    "\n",
    "normalized_df=(data_sin_riesgo-data_sin_riesgo.min())/(data_sin_riesgo.max()-data_sin_riesgo.min())\n",
    "\n",
    "sns.boxplot(normalized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"riesgo\"] = data[\"riesgo\"].map({'alto':1,'bajo':0})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = normalized_df.copy()\n",
    "y = data[\"riesgo\"].copy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=1)\n",
    "\n",
    "print(x.shape, x_train.shape, x_test.shape)\n",
    "print(y.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar un modelo de Regresión Logística\n",
    "model_log_reg = LogisticRegression(verbose=2)\n",
    "\n",
    "# Entrenar el modelo con el conjunto de entrenamiento\n",
    "model_log_reg.fit(x_train, y_train)\n",
    "\n",
    "# Calculando la precisión para el conjunto de entrenamiento\n",
    "x_train_prediction = model_log_reg.predict(x_train)\n",
    "train_accuracy = accuracy_score(x_train_prediction, y_train)\n",
    "train_recall = recall_score(x_train_prediction, y_train)\n",
    "train_f1 = f1_score(x_train_prediction, y_train)\n",
    "print(f'Entrenamiento - Accuracy: {train_accuracy:.2f}')\n",
    "print(f'Entrenamiento - Recall: {train_recall:.2f}')\n",
    "print(f'Entrenamiento - F1-Score: {train_f1:.2f}')\n",
    "\n",
    "# Calculando la precisión para el conjunto de test\n",
    "x_test_prediction = model_log_reg.predict(x_test)\n",
    "test_accuracy = accuracy_score(x_test_prediction, y_test)\n",
    "test_recall = recall_score(x_test_prediction, y_test)\n",
    "test_f1 = f1_score(x_test_prediction, y_test)\n",
    "print(f'Test - Accuracy: {test_accuracy:.2f}')\n",
    "print(f'Test - Recall: {test_recall:.2f}')\n",
    "print(f'Test - F1-Score: {test_f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logística con regularización Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar un modelo de Regresión Logística\n",
    "model_log_reg = LogisticRegression(penalty=\"l1\", C=1, verbose=2, solver=\"liblinear\")\n",
    "\n",
    "# Entrenar el modelo con el conjunto de entrenamiento\n",
    "model_log_reg.fit(x_train, y_train)\n",
    "\n",
    "# Calculando la precisión para el conjunto de entrenamiento\n",
    "x_train_prediction = model_log_reg.predict(x_train)\n",
    "train_accuracy = accuracy_score(x_train_prediction, y_train)\n",
    "train_recall = recall_score(x_train_prediction, y_train)\n",
    "train_f1 = f1_score(x_train_prediction, y_train)\n",
    "print(f'Entrenamiento - Accuracy: {train_accuracy:.2f}')\n",
    "print(f'Entrenamiento - Recall: {train_recall:.2f}')\n",
    "print(f'Entrenamiento - F1-Score: {train_f1:.2f}')\n",
    "\n",
    "# Calculando la precisión para el conjunto de test\n",
    "x_test_prediction = model_log_reg.predict(x_test)\n",
    "test_accuracy = accuracy_score(x_test_prediction, y_test)\n",
    "test_recall = recall_score(x_test_prediction, y_test)\n",
    "test_f1 = f1_score(x_test_prediction, y_test)\n",
    "print(f'Test - Accuracy: {test_accuracy:.2f}')\n",
    "print(f'Test - Recall: {test_recall:.2f}')\n",
    "print(f'Test - F1-Score: {test_f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos un modelo Naive Bayes\n",
    "model_NB = GaussianNB()\n",
    "\n",
    "# Entrenar el modelo con el conjunto de entrenamiento\n",
    "model_NB.fit(x_train, y_train)\n",
    "\n",
    "# Calculando la precisión para el conjunto de entrenamiento\n",
    "x_train_prediction = model_NB.predict(x_train)\n",
    "train_accuracy = accuracy_score(x_train_prediction, y_train)\n",
    "train_recall = recall_score(x_train_prediction, y_train)\n",
    "train_f1 = f1_score(x_train_prediction, y_train)\n",
    "print(f'Entrenamiento - Accuracy: {train_accuracy:.2f}')\n",
    "print(f'Entrenamiento - Recall: {train_recall:.2f}')\n",
    "print(f'Entrenamiento - F1-Score: {train_f1:.2f}')\n",
    "\n",
    "# Calculando la precisión para el conjunto de test\n",
    "x_test_prediction = model_NB.predict(x_test)\n",
    "test_accuracy = accuracy_score(x_test_prediction, y_test)\n",
    "test_recall = recall_score(x_test_prediction, y_test)\n",
    "test_f1 = f1_score(x_test_prediction, y_test)\n",
    "print(f'Test - Accuracy: {test_accuracy:.2f}')\n",
    "print(f'Test - Recall: {test_recall:.2f}')\n",
    "print(f'Test - F1-Score: {test_f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest-Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = [i for i in range(1, 21)]\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=7, scoring=\"recall\")\n",
    "\n",
    "grid_search = grid.fit(x_train, y_train)\n",
    "\n",
    "print(\"Score en el conjunto de tests: {:.2f}\".format(grid_search.score(x_test, y_test)))\n",
    "print(\"Mejores parámetros: {}\".format(grid_search.best_params_))\n",
    "print(\"Mejor Score de validacion Cruzada: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos un modelo KNN\n",
    "model_KNN = KNeighborsClassifier(grid_search.best_params_[\"n_neighbors\"])\n",
    "\n",
    "# Entrenar el modelo con el conjunto de entrenamiento\n",
    "model_KNN.fit(x_train, y_train)\n",
    "\n",
    "# Calculando la precisión para el conjunto de entrenamiento\n",
    "x_train_prediction = model_KNN.predict(x_train)\n",
    "train_accuracy = accuracy_score(x_train_prediction, y_train)\n",
    "train_recall = recall_score(x_train_prediction, y_train)\n",
    "train_f1 = f1_score(x_train_prediction, y_train)\n",
    "print(f'Entrenamiento - Accuracy: {train_accuracy:.2f}')\n",
    "print(f'Entrenamiento - Recall: {train_recall:.2f}')\n",
    "print(f'Entrenamiento - F1-Score: {train_f1:.2f}')\n",
    "\n",
    "# Calculando la precisión para el conjunto de test\n",
    "x_test_prediction = model_KNN.predict(x_test)\n",
    "test_accuracy = accuracy_score(x_test_prediction, y_test)\n",
    "test_recall = recall_score(x_test_prediction, y_test)\n",
    "test_f1 = f1_score(x_test_prediction, y_test)\n",
    "print(f'Test - Accuracy: {test_accuracy:.2f}')\n",
    "print(f'Test - Recall: {test_recall:.2f}')\n",
    "print(f'Test - F1-Score: {test_f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos un modelo RandomForest\n",
    "model_RFC = RandomForestClassifier(n_estimators=150)\n",
    "\n",
    "# Entrenar el modelo con el conjunto de entrenamiento\n",
    "model_RFC.fit(x_train, y_train)\n",
    "\n",
    "# Calculando la precisión para el conjunto de entrenamiento\n",
    "x_train_prediction = model_RFC.predict(x_train)\n",
    "train_accuracy = accuracy_score(x_train_prediction, y_train)\n",
    "train_recall = recall_score(x_train_prediction, y_train)\n",
    "train_f1 = f1_score(x_train_prediction, y_train)\n",
    "print(f'Entrenamiento - Accuracy: {train_accuracy:.2f}')\n",
    "print(f'Entrenamiento - Recall: {train_recall:.2f}')\n",
    "print(f'Entrenamiento - F1-Score: {train_f1:.2f}')\n",
    "\n",
    "# Calculando la precisión para el conjunto de test\n",
    "x_test_prediction = model_RFC.predict(x_test)\n",
    "test_accuracy = accuracy_score(x_test_prediction, y_test)\n",
    "test_recall = recall_score(x_test_prediction, y_test)\n",
    "test_f1 = f1_score(x_test_prediction, y_test)\n",
    "print(f'Test - Accuracy: {test_accuracy:.2f}')\n",
    "print(f'Test - Recall: {test_recall:.2f}')\n",
    "print(f'Test - F1-Score: {test_f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {'n_estimators': randint(50,500),\n",
    "              'max_depth': randint(1,20)}\n",
    "\n",
    "# Usar random search para encontrar los mejores hiperparámetros\n",
    "rand_search = RandomizedSearchCV(RandomForestClassifier(), \n",
    "                                 param_distributions = param_dist, \n",
    "                                 n_iter=5, \n",
    "                                 cv=5)\n",
    "\n",
    "# Entrenar random search\n",
    "rand_search.fit(x_train, y_train)\n",
    "\n",
    "# Crear una variable con el mejor modelo\n",
    "best_rf = rand_search.best_estimator_\n",
    "\n",
    "# Mostrar los mejores hiperparámetros\n",
    "print('Best hyperparameters:',  rand_search.best_params_)\n",
    "\n",
    "# Entrenar el modelo con el conjunto de entrenamiento\n",
    "best_rf.fit(x_train, y_train)\n",
    "\n",
    "# Calculando la precisión para el conjunto de entrenamiento\n",
    "x_train_prediction = best_rf.predict(x_train)\n",
    "train_accuracy = accuracy_score(x_train_prediction, y_train)\n",
    "train_recall = recall_score(x_train_prediction, y_train)\n",
    "train_f1 = f1_score(x_train_prediction, y_train)\n",
    "print(f'Entrenamiento - Accuracy: {train_accuracy:.2f}')\n",
    "print(f'Entrenamiento - Recall: {train_recall:.2f}')\n",
    "print(f'Entrenamiento - F1-Score: {train_f1:.2f}')\n",
    "\n",
    "# Calculando la precisión para el conjunto de test\n",
    "x_test_prediction = best_rf.predict(x_test)\n",
    "test_accuracy = accuracy_score(x_test_prediction, y_test)\n",
    "test_recall = recall_score(x_test_prediction, y_test)\n",
    "test_f1 = f1_score(x_test_prediction, y_test)\n",
    "print(f'Test - Accuracy: {test_accuracy:.2f}')\n",
    "print(f'Test - Recall: {test_recall:.2f}')\n",
    "print(f'Test - F1-Score: {test_f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrón Multicapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar un modelo de perceptron multicapa\n",
    "model_MLP = MLPClassifier(hidden_layer_sizes=(50, 100, 50), activation=\"relu\", max_iter=500, alpha=0.000001, solver=\"adam\", verbose=0, random_state=2, tol=0.000000001)\n",
    "\n",
    "# Entrenar el modelo con el conjunto de entrenamiento\n",
    "model_MLP.fit(x_train, y_train)\n",
    "\n",
    "# Calculando la precisión para el conjunto de entrenamiento\n",
    "x_train_prediction = model_MLP.predict(x_train)\n",
    "train_accuracy = accuracy_score(x_train_prediction, y_train)\n",
    "train_recall = recall_score(x_train_prediction, y_train)\n",
    "train_f1 = f1_score(x_train_prediction, y_train)\n",
    "print(f'Entrenamiento - Accuracy: {train_accuracy:.2f}')\n",
    "print(f'Entrenamiento - Recall: {train_recall:.2f}')\n",
    "print(f'Entrenamiento - F1-Score: {train_f1:.2f}')\n",
    "\n",
    "# Calculando la precisión para el conjunto de test\n",
    "x_test_prediction = model_MLP.predict(x_test)\n",
    "test_accuracy = accuracy_score(x_test_prediction, y_test)\n",
    "test_recall = recall_score(x_test_prediction, y_test)\n",
    "test_f1 = f1_score(x_test_prediction, y_test)\n",
    "print(f'Test - Accuracy: {test_accuracy:.2f}')\n",
    "print(f'Test - Recall: {test_recall:.2f}')\n",
    "print(f'Test - F1-Score: {test_f1:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
